{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "root_random = 50\n",
    "np.random.seed(root_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1\n",
    "\n",
    "- Becoming familiar with tensor based operations and generating synthetic data.\n",
    "- Are input features uninformative? Are the hyper-parameters set correctly? Is there an inherent bug?\n",
    "- Test by passing data with known correct distribution and compare correctness\n",
    "\n",
    "# Problem\n",
    "- This task is a regression task\n",
    "- Use Tensors on Synthetic data I produce\n",
    "- Come up with a mapping function from Rm to Rn, where m and n are set and both are > 3.\n",
    "- Provide the equation of the functions\n",
    "- Add random noise to the output to make the problem more interesting\n",
    "- Ensure underlying function is still recognisable\n",
    "- Be careful of expected value of noise\n",
    "- Pass data to the algorithm to test the output model\n",
    "\n",
    "# Notes\n",
    "- Do not use regression libraries. Must all be implemented using tensors.\n",
    "- Avoid using loops where tensor operations could act on multiple values at once.\n",
    "- Avoid using matrix inverse operators. Use gradients instead.\n",
    "- Be mindful of gradient tracking.\n",
    "- Be sure to generate enough data.\n",
    "- Choose appropriate learning rate\n",
    "- Choose appropriate learning termination criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.4599,  2.3697,  2.4377,  3.5781],\n",
      "        [ 4.1376, 10.2874,  4.3195,  8.0593],\n",
      "        [ 7.5069,  3.3487,  3.5250,  3.6309],\n",
      "        [ 1.2528,  9.8290,  9.0175,  5.6381],\n",
      "        [ 3.1226,  8.8819,  7.1632,  3.6738],\n",
      "        [ 4.6215,  5.2037,  9.1882,  5.7008],\n",
      "        [ 6.2539,  0.6047,  3.7576,  0.2731],\n",
      "        [ 1.5107,  9.7205,  9.5871,  7.2339],\n",
      "        [ 7.2077,  4.7562,  9.3157,  3.6540],\n",
      "        [ 6.6292,  6.8273,  5.6631,  2.6249],\n",
      "        [ 6.9119,  8.2971,  7.8372,  3.8622],\n",
      "        [ 8.8061,  7.4976,  6.9240,  1.6322],\n",
      "        [ 9.5690,  3.6125,  2.8566,  6.1385],\n",
      "        [ 5.0087,  2.3454,  8.0638,  1.7443],\n",
      "        [ 2.6736,  6.6937,  4.7038,  0.6401],\n",
      "        [ 1.1981,  0.9410,  4.6929,  5.5411],\n",
      "        [ 9.8760,  5.3750,  5.5012,  9.4952],\n",
      "        [ 8.9370,  3.0052,  7.0013, 10.0355],\n",
      "        [ 2.0127,  6.7119,  8.1873,  9.8248],\n",
      "        [ 8.0601,  4.6286,  0.2827,  0.8041]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#Produce Synthetic Data\n",
    "#Functions \n",
    "#Target (R5) = Input (R4)\n",
    "#Y1 = X1\n",
    "#Y2 = 2*(X2 - X1)\n",
    "#Y3 = X2/(X1 - X4)\n",
    "#Y4 = X3 + X4 - X1\n",
    "#Y5 = X4 - X2 * X3\n",
    "\n",
    "def generate_synthetic_data():\n",
    "    #Generate data\n",
    "    dataset = 10*np.random.random_sample((20, 4))\n",
    "    return dataset\n",
    "\n",
    "def add_noise(data):\n",
    "    adding = np.random.random_sample((20, 4))-0.5\n",
    "    out = np.add(data, adding)\n",
    "            \n",
    "    return out\n",
    "\n",
    "dataset = generate_synthetic_data()\n",
    "results = np.zeros((20, 5))\n",
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        if j == 0:\n",
    "            results[i][j] = dataset[i][0]\n",
    "        elif j == 1:\n",
    "            results[i][j] = 2 * (dataset[i][1] - dataset[i][0])\n",
    "        elif j == 2:\n",
    "            results[i][j] = dataset[i][1]/(dataset[i][0] - dataset[i][3])\n",
    "        elif j == 3:\n",
    "            results[i][j] = dataset[i][2] + dataset[i][3] - dataset[i][0]\n",
    "        elif j == 4:\n",
    "            results[i][j] = dataset[i][3] - dataset[i][1] * dataset[i][2]\n",
    "        \n",
    "noisey_dataset = add_noise(dataset)\n",
    "noisey_results = np.zeros((20, 5))\n",
    "for i in range(20):\n",
    "    for j in range(5):\n",
    "        if j == 0:\n",
    "            noisey_results[i][j] = noisey_dataset[i][0]\n",
    "        elif j == 1:\n",
    "            noisey_results[i][j] = 2 * (noisey_dataset[i][1] - noisey_dataset[i][0])\n",
    "        elif j == 2:\n",
    "            noisey_results[i][j] = noisey_dataset[i][1]/(noisey_dataset[i][0] - noisey_dataset[i][3])\n",
    "        elif j == 3:\n",
    "            noisey_results[i][j] = noisey_dataset[i][2] + noisey_dataset[i][3] - noisey_dataset[i][0]\n",
    "        elif j == 4:\n",
    "            noisey_results[i][j] = noisey_dataset[i][3] - noisey_dataset[i][1] * noisey_dataset[i][2]\n",
    "\n",
    "#Convert to tensors\n",
    "inputs = torch.from_numpy(noisey_dataset)\n",
    "targets = torch.from_numpy(noisey_results)\n",
    "actual_model = torch.from_numpy(results)\n",
    "print(inputs)\n",
    "\n",
    "#Tensors now ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1313, 0.2397, 0.1117, 0.6244],\n",
      "        [0.8666, 0.4330, 0.2931, 0.1306],\n",
      "        [0.5411, 0.0471, 0.2354, 0.7742],\n",
      "        [0.8874, 0.8023, 0.1517, 0.6454],\n",
      "        [0.7711, 0.6292, 0.8463, 0.5902]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#Regression Model\n",
    "\n",
    "#Weights and Biases\n",
    "weight = torch.rand(5, 4, requires_grad=True)\n",
    "bias = torch.rand(5, requires_grad=True)\n",
    "\n",
    "print(weight)\n",
    "\n",
    "#Model\n",
    "def model(val):\n",
    "    return val @ (weight.t()).double() + bias.double()\n",
    "\n",
    "preds = model(inputs)\n",
    "#print(preds)\n",
    "#print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(716.2540, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(62.1511, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(36.3239, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(25.4625, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(20.6834, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(18.4631, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(17.3672, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(16.7910, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(16.4683, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(16.2759, dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "tensor(16.1537, dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Loss calculations\n",
    "\n",
    "#Mean square error loss function\n",
    "def mse(pred, target):\n",
    "    diff = pred - target\n",
    "    return torch.sum(diff * diff) / diff.numel()\n",
    "\n",
    "#Calc loss\n",
    "loss = mse(preds, targets)\n",
    "print(loss)\n",
    "\n",
    "#Compute gradient\n",
    "loss.backward()\n",
    "\n",
    "# Train for 100 epochs\n",
    "for i in range(100):  \n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        weight -= weight.grad * 1e-2\n",
    "        bias -= bias.grad * 1e-2\n",
    "        weight.grad.zero_()\n",
    "        bias.grad.zero_()\n",
    "\n",
    "        if (i+1)%10==0:\n",
    "            print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2\n",
    "\n",
    "- Small scale transfer learning\n",
    "- Train a CNN on a simple problem and try to transfer the learning to ma larger and more difficult problem\n",
    "- USE NN OPTIMISATION FROM pytorch\n",
    "\n",
    "# Problem\n",
    "- Define two network classes\n",
    "    - torchvision.datasets.MNIST\n",
    "    - torchvision.datasets.CIFAR10\n",
    "- Train first network to a good performance\n",
    "- Train second network to observe losses over time (epochs)\n",
    "- Test to see if copying layers from MNIST to CIFAR10 (before training) improves training of the second network.\n",
    "\n",
    "# Notes\n",
    "- Which layers are good to be transfered? (all but last 2?)\n",
    "- How to deal with differing dimensionality?\n",
    "- How to copy objects across?\n",
    "- Presenting findings coherently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, again\n"
     ]
    }
   ],
   "source": [
    "print (\"Hi, again\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3\n",
    "\n",
    "- Option A Cost Sensitive Learning\n",
    "\n",
    "# Problem\n",
    "- C is a k-by-k cost matrix for a classification class with k classes\n",
    "- the element C(i,j) is the cost of classifying an instance of class j as class i\n",
    "- Want to minimise the expected cost of predictions\n",
    "\n",
    "- Write Psuedocode that, when optomised, achieves minimum expected cost of prediction\n",
    "- Assuming a learning algorithm which minimises cost prediction is given, write a different way of achieving minimum expected cost prediction\n",
    "\n",
    "\n",
    "# Notes\n",
    "- Consider cases with k > 1 and briely discuss scalability.\n",
    "- Do not have to use tensors\n",
    "- Can write in pseudo-Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
